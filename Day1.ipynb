{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDay1 = \"21752342814933766938172121674976879111362417653261522357855816893656462449168377359285244818489723869987861247912289729579296691684761143544956991583942215236568961875851755854977946147178746464675227699149925227227137557479769948569788884399379821111382536722699575759474473273939756348992714667963596189765734743169489599125771443348193383566159843593541134749392569865481578359825844394454173219857919349341442148282229689541561169341622222354651397342928678496478671339383923769856425795211323673389723181967933933832711545885653952861879231537976292517866354812943192728263269524735698423336673735158993853556148833861327959262254756647827739145283577793481526768156921138428318939361859721778556264519643435871835744859243167227889562738712953651128317624673985213525897522378259178625416722152155728615936587369515254936828668564857283226439881266871945998796488472249182538883354186573925183152663862683995449671663285775397453876262722567452435914777363522817594741946638986571793655889466419895996924122915777224499481496837343194149123735355268151941712871245863553836953349887831949788869852929147849489265325843934669999391846286319268686789372513976522282587526866148166337215961493536262851512218794139272361292811529888161198799297966893366553115353639298256788819385272471187213579185523521341651117947676785341146235441411441813242514813227821843819424619974979886871646621918865274574538951761567855845681272364646138584716333599843835167373525248547542442942583122624534494442516259616973235858469131159773167334953658673271599748942956981954699444528689628848694446818825465485122869742839711471129862632128635779658365756362863627135983617613332849756371986376967117549251566281992964573929655589313871976556784849231916513831538254812347116253949818633527185174221565279775766742262687713114114344843534958833372634182176866315441583887177759222598853735114191874277711434653854816841589229914164681364497429324463193669337827467661773833517841763711156376147664749175267212562321567728575765844893232718971471289841171642868948852136818661741238178676857381583155547755219837116125995361896562498721571413742\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lastDigit = \" \"\n",
    "summands = []\n",
    "for c in inputDay1:\n",
    "    if lastDigit == c:\n",
    "        summands.append(c)\n",
    "    lastDigit = c\n",
    "if inputDay1[-1] == inputDay1[0]:\n",
    "    summands.append(inputDay1[-1])\n",
    "\n",
    "sum = 0\n",
    "for s in summands:\n",
    "    sum = sum + int(s)\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420\n"
     ]
    }
   ],
   "source": [
    "step = len(inputDay1)/2\n",
    "summands = []\n",
    "for idx, val in enumerate(inputDay1):\n",
    "    nextIndex = int((idx + step) % len(inputDay1))\n",
    "    if val == inputDay1[nextIndex]:\n",
    "        summands.append(val)\n",
    "        \n",
    "sum = 0\n",
    "for s in summands:\n",
    "    sum = sum + int(s)\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSample(seq_len):\n",
    "    x = np.random.choice(10, seq_len)\n",
    "    summands = []\n",
    "    lastVal = 0\n",
    "    for c in x:\n",
    "        if lastVal == c:\n",
    "            summands.append(c)\n",
    "        else:\n",
    "            summands.append(0)\n",
    "        lastVal = c\n",
    "    y = 0\n",
    "    for s in summands:\n",
    "        y = y + int(s)\n",
    "    return np.array(x).reshape(seq_len, 1), np.array(y).reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "x,y = generateSample(5)\n",
    "x.shape\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(trainNumber, testNumber, seq_len):\n",
    "    y_train = []\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(trainNumber):\n",
    "        x,y = generateSample(seq_len)\n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "    for i in range(testNumber):\n",
    "        x,y = generateSample(seq_len)\n",
    "        x_test.append(x)\n",
    "        y_test.append(y)\n",
    "        \n",
    "    return [\n",
    "        np.array(x_train), \n",
    "        np.array(y_train), \n",
    "        np.array(x_test), \n",
    "        np.array(y_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(10,10,15)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[1],\n",
    "        input_shape=layers[0],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_point_by_point(model, data):\n",
    "    #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
    "    predicted = model.predict(data)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "def predict_sequence_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(predicted_data, true_data):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "> Data Loaded. Compiling...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_68 (LSTM)               (None, 50, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 70,901\n",
      "Trainable params: 70,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Inputs: (None, 50, 1)\n",
      "Outputs: (None, 1)\n",
      "Actual input: (1000, 50, 1)\n",
      "Actual output: (1000, 1)\n",
      "(1000, 50, 1)\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "950/950 [==============================] - 3s - loss: 586.4889 - val_loss: 504.1070\n",
      "Epoch 2/100\n",
      "950/950 [==============================] - 1s - loss: 468.2833 - val_loss: 381.5463\n",
      "Epoch 3/100\n",
      "950/950 [==============================] - 1s - loss: 361.7190 - val_loss: 316.8449\n",
      "Epoch 4/100\n",
      "950/950 [==============================] - 1s - loss: 303.5009 - val_loss: 274.3348\n",
      "Epoch 5/100\n",
      "950/950 [==============================] - 1s - loss: 263.9121 - val_loss: 238.8453\n",
      "Epoch 6/100\n",
      "950/950 [==============================] - 1s - loss: 230.8662 - val_loss: 215.2516\n",
      "Epoch 7/100\n",
      "950/950 [==============================] - 1s - loss: 209.7529 - val_loss: 201.4297\n",
      "Epoch 8/100\n",
      "950/950 [==============================] - 1s - loss: 196.8492 - val_loss: 192.6465\n",
      "Epoch 9/100\n",
      "950/950 [==============================] - 1s - loss: 190.0202 - val_loss: 186.3897\n",
      "Epoch 10/100\n",
      "950/950 [==============================] - 1s - loss: 182.9801 - val_loss: 181.7794\n",
      "Epoch 11/100\n",
      "950/950 [==============================] - 1s - loss: 179.4412 - val_loss: 177.9833\n",
      "Epoch 12/100\n",
      "950/950 [==============================] - 2s - loss: 175.4849 - val_loss: 175.0316\n",
      "Epoch 13/100\n",
      "950/950 [==============================] - 1s - loss: 173.4788 - val_loss: 172.4163\n",
      "Epoch 14/100\n",
      "950/950 [==============================] - 1s - loss: 169.0085 - val_loss: 170.0320\n",
      "Epoch 15/100\n",
      "950/950 [==============================] - 1s - loss: 169.4138 - val_loss: 167.7556\n",
      "Epoch 16/100\n",
      "950/950 [==============================] - 1s - loss: 165.4906 - val_loss: 165.6096\n",
      "Epoch 17/100\n",
      "950/950 [==============================] - 1s - loss: 164.0923 - val_loss: 163.5805\n",
      "Epoch 18/100\n",
      "950/950 [==============================] - 2s - loss: 160.8867 - val_loss: 161.6293\n",
      "Epoch 19/100\n",
      "950/950 [==============================] - 2s - loss: 159.5812 - val_loss: 159.7897\n",
      "Epoch 20/100\n",
      "950/950 [==============================] - 1s - loss: 157.9722 - val_loss: 157.9872\n",
      "Epoch 21/100\n",
      "950/950 [==============================] - 1s - loss: 156.7413 - val_loss: 156.2612\n",
      "Epoch 22/100\n",
      "950/950 [==============================] - 1s - loss: 154.9847 - val_loss: 154.6002\n",
      "Epoch 23/100\n",
      "950/950 [==============================] - 1s - loss: 152.5928 - val_loss: 153.0085\n",
      "Epoch 24/100\n",
      "950/950 [==============================] - 1s - loss: 149.9664 - val_loss: 151.4807\n",
      "Epoch 25/100\n",
      "950/950 [==============================] - 1s - loss: 150.8986 - val_loss: 150.0301\n",
      "Epoch 26/100\n",
      "950/950 [==============================] - 1s - loss: 148.3075 - val_loss: 148.6006\n",
      "Epoch 27/100\n",
      "950/950 [==============================] - 1s - loss: 147.7881 - val_loss: 147.2844\n",
      "Epoch 28/100\n",
      "950/950 [==============================] - 1s - loss: 145.7239 - val_loss: 145.9850\n",
      "Epoch 29/100\n",
      "950/950 [==============================] - 1s - loss: 144.0324 - val_loss: 144.7336\n",
      "Epoch 30/100\n",
      "950/950 [==============================] - 2s - loss: 143.9394 - val_loss: 143.5658\n",
      "Epoch 31/100\n",
      "950/950 [==============================] - 1s - loss: 141.5530 - val_loss: 142.4876\n",
      "Epoch 32/100\n",
      "950/950 [==============================] - 1s - loss: 141.9805 - val_loss: 141.4832\n",
      "Epoch 33/100\n",
      "950/950 [==============================] - 1s - loss: 139.5827 - val_loss: 140.4935\n",
      "Epoch 34/100\n",
      "950/950 [==============================] - 1s - loss: 139.9891 - val_loss: 139.5780\n",
      "Epoch 35/100\n",
      "950/950 [==============================] - 1s - loss: 137.9514 - val_loss: 138.7219\n",
      "Epoch 36/100\n",
      "950/950 [==============================] - 1s - loss: 136.7971 - val_loss: 137.9210\n",
      "Epoch 37/100\n",
      "950/950 [==============================] - 1s - loss: 136.9399 - val_loss: 137.1510\n",
      "Epoch 38/100\n",
      "950/950 [==============================] - 1s - loss: 135.7859 - val_loss: 136.4404\n",
      "Epoch 39/100\n",
      "950/950 [==============================] - 1s - loss: 134.6924 - val_loss: 135.7572\n",
      "Epoch 40/100\n",
      "950/950 [==============================] - 1s - loss: 134.6434 - val_loss: 135.1904\n",
      "Epoch 41/100\n",
      "950/950 [==============================] - 1s - loss: 134.3210 - val_loss: 134.6333\n",
      "Epoch 42/100\n",
      "950/950 [==============================] - 1s - loss: 133.4781 - val_loss: 134.1333\n",
      "Epoch 43/100\n",
      "950/950 [==============================] - 1s - loss: 132.6737 - val_loss: 133.6740\n",
      "Epoch 44/100\n",
      "950/950 [==============================] - 1s - loss: 133.9465 - val_loss: 133.2729\n",
      "Epoch 45/100\n",
      "950/950 [==============================] - 1s - loss: 133.7582 - val_loss: 132.9106\n",
      "Epoch 46/100\n",
      "950/950 [==============================] - 1s - loss: 133.4002 - val_loss: 132.6288\n",
      "Epoch 47/100\n",
      "950/950 [==============================] - 1s - loss: 132.2421 - val_loss: 132.3515\n",
      "Epoch 48/100\n",
      "950/950 [==============================] - 1s - loss: 132.4150 - val_loss: 132.1108\n",
      "Epoch 49/100\n",
      "950/950 [==============================] - 1s - loss: 130.9522 - val_loss: 131.8734\n",
      "Epoch 50/100\n",
      "950/950 [==============================] - 1s - loss: 132.3308 - val_loss: 131.7236\n",
      "Epoch 51/100\n",
      "950/950 [==============================] - 1s - loss: 131.4992 - val_loss: 131.5778\n",
      "Epoch 52/100\n",
      "950/950 [==============================] - 1s - loss: 129.9957 - val_loss: 131.4449\n",
      "Epoch 53/100\n",
      "950/950 [==============================] - 1s - loss: 131.9601 - val_loss: 131.3405\n",
      "Epoch 54/100\n",
      "950/950 [==============================] - 1s - loss: 131.5735 - val_loss: 131.2578\n",
      "Epoch 55/100\n",
      "950/950 [==============================] - 1s - loss: 130.2647 - val_loss: 131.1763\n",
      "Epoch 56/100\n",
      "950/950 [==============================] - 1s - loss: 129.8031 - val_loss: 131.1056\n",
      "Epoch 57/100\n",
      "950/950 [==============================] - 1s - loss: 131.3563 - val_loss: 131.0987\n",
      "Epoch 58/100\n",
      "950/950 [==============================] - 1s - loss: 130.2744 - val_loss: 131.0619\n",
      "Epoch 59/100\n",
      "950/950 [==============================] - 1s - loss: 132.0165 - val_loss: 131.5459\n",
      "Epoch 60/100\n",
      "950/950 [==============================] - 1s - loss: 132.5718 - val_loss: 131.3640\n",
      "Epoch 61/100\n",
      "950/950 [==============================] - 1s - loss: 129.6718 - val_loss: 192.3182\n",
      "Epoch 62/100\n",
      "950/950 [==============================] - 1s - loss: 165.0697 - val_loss: 130.6451\n",
      "Epoch 63/100\n",
      "950/950 [==============================] - 1s - loss: 131.7620 - val_loss: 129.8859\n",
      "Epoch 64/100\n",
      "950/950 [==============================] - 1s - loss: 128.9262 - val_loss: 129.1060\n",
      "Epoch 65/100\n",
      "950/950 [==============================] - 1s - loss: 127.4366 - val_loss: 127.0006\n",
      "Epoch 66/100\n",
      "950/950 [==============================] - 1s - loss: 125.7070 - val_loss: 128.7538\n",
      "Epoch 67/100\n",
      "950/950 [==============================] - 2s - loss: 128.1617 - val_loss: 127.6904\n",
      "Epoch 68/100\n",
      "950/950 [==============================] - 1s - loss: 128.8481 - val_loss: 129.8112\n",
      "Epoch 69/100\n",
      "950/950 [==============================] - 1s - loss: 127.1291 - val_loss: 125.9248\n",
      "Epoch 70/100\n",
      "950/950 [==============================] - 1s - loss: 127.9283 - val_loss: 125.2064\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 1s - loss: 125.0657 - val_loss: 121.6341\n",
      "Epoch 72/100\n",
      "950/950 [==============================] - 1s - loss: 121.7309 - val_loss: 123.5263\n",
      "Epoch 73/100\n",
      "950/950 [==============================] - 1s - loss: 139.6327 - val_loss: 125.7700\n",
      "Epoch 74/100\n",
      "950/950 [==============================] - 1s - loss: 126.1283 - val_loss: 121.6270\n",
      "Epoch 75/100\n",
      "950/950 [==============================] - 1s - loss: 122.0618 - val_loss: 126.1873\n",
      "Epoch 76/100\n",
      "950/950 [==============================] - 1s - loss: 125.1563 - val_loss: 128.6475\n",
      "Epoch 77/100\n",
      "950/950 [==============================] - 1s - loss: 123.7351 - val_loss: 122.7041\n",
      "Epoch 78/100\n",
      "950/950 [==============================] - 1s - loss: 122.5776 - val_loss: 121.5168\n",
      "Epoch 79/100\n",
      "950/950 [==============================] - 1s - loss: 123.6697 - val_loss: 123.7525\n",
      "Epoch 80/100\n",
      "950/950 [==============================] - 1s - loss: 126.7551 - val_loss: 120.8496\n",
      "Epoch 81/100\n",
      "950/950 [==============================] - 1s - loss: 120.8404 - val_loss: 119.6033\n",
      "Epoch 82/100\n",
      "950/950 [==============================] - 1s - loss: 121.1270 - val_loss: 124.1989\n",
      "Epoch 83/100\n",
      "950/950 [==============================] - 2s - loss: 130.5364 - val_loss: 122.5407\n",
      "Epoch 84/100\n",
      "950/950 [==============================] - 2s - loss: 122.1520 - val_loss: 117.6139\n",
      "Epoch 85/100\n",
      "950/950 [==============================] - 2s - loss: 117.7323 - val_loss: 122.3929\n",
      "Epoch 86/100\n",
      "950/950 [==============================] - 2s - loss: 123.4532 - val_loss: 116.2736\n",
      "Epoch 87/100\n",
      "950/950 [==============================] - 2s - loss: 119.2324 - val_loss: 129.1591\n",
      "Epoch 88/100\n",
      "950/950 [==============================] - 1s - loss: 123.4627 - val_loss: 115.2410\n",
      "Epoch 89/100\n",
      "950/950 [==============================] - 1s - loss: 116.6939 - val_loss: 117.8447\n",
      "Epoch 90/100\n",
      "950/950 [==============================] - 2s - loss: 123.8061 - val_loss: 121.9556\n",
      "Epoch 91/100\n",
      "950/950 [==============================] - 1s - loss: 122.6348 - val_loss: 126.8559\n",
      "Epoch 92/100\n",
      "950/950 [==============================] - 1s - loss: 120.6484 - val_loss: 121.0166\n",
      "Epoch 93/100\n",
      "950/950 [==============================] - 1s - loss: 122.6170 - val_loss: 130.5900\n",
      "Epoch 94/100\n",
      "950/950 [==============================] - 2s - loss: 125.4529 - val_loss: 118.0235\n",
      "Epoch 95/100\n",
      "950/950 [==============================] - 1s - loss: 119.1950 - val_loss: 120.1442\n",
      "Epoch 96/100\n",
      "950/950 [==============================] - 1s - loss: 124.0167 - val_loss: 117.5436\n",
      "Epoch 97/100\n",
      "950/950 [==============================] - 1s - loss: 117.3128 - val_loss: 115.1191\n",
      "Epoch 98/100\n",
      "950/950 [==============================] - 1s - loss: 117.2829 - val_loss: 124.2353\n",
      "Epoch 99/100\n",
      "950/950 [==============================] - 2s - loss: 121.4262 - val_loss: 116.2306\n",
      "Epoch 100/100\n",
      "950/950 [==============================] - 1s - loss: 116.4933 - val_loss: 116.7263\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCL+P80g0s0sLArcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182c954ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs  = 100\n",
    "seq_len = 50\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_data(1000, 10, seq_len)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = build_model([X_train.shape[1:],50, 100, 1])\n",
    "\n",
    "model.summary()\n",
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print(\"Outputs: {}\".format(model.output_shape))\n",
    "print(\"Actual input: {}\".format(X_train.shape))\n",
    "print(\"Actual output: {}\".format(Y_train.shape))\n",
    "\n",
    "print (X_train.shape)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.05)\n",
    "fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()  \n",
    "\n",
    "predictions = predict_sequences_multiple(model, X_test, seq_len, 50)\n",
    "#predicted = lstm.predict_sequence_full(model, X_test, seq_len)\n",
    "#predicted = lstm.predict_point_by_point(model, X_test)        \n",
    "\n",
    "plot_results_multiple(predictions, Y_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
